# -*- coding: utf-8 -*-
"""Text_classification final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1czhK6fxCNtTQThPBZHDZZemKsy8DtV8x

**Step 1-Load the necessary libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import re
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import nltk
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Bidirectional, LSTM, Embedding, BatchNormalization, Dropout, Dense
from tensorflow.keras.models import Sequential
from sklearn.metrics import classification_report, accuracy_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
import seaborn as sns

"""**Step 2- load the Dataset**"""

data = pd.read_csv('/content/text.csv')

# Check the first few rows
print(data.head())

"""**Step 3- Check the missing and duplicated values**

Missing values indicate incomplete data, which can lead to incorrect model training and predictions because the model relies on complete feature sets to learn patterns.

Duplicate rows can inflate the weight of certain samples in the dataset, leading to biased model performance.
"""

#check if there is missing value
data.isna().sum()
#check if there is duplicated rows
data.duplicated().sum()
#drop unnecessary column "Unnamed: 0" column
data.drop("Unnamed: 0",axis=1,inplace = True)

"""**Step 4- Mapping Numerical Labels to Emotion Types**


"""

# The emotions are artfully categorized into six distinctive hues: Sadness (0), Joy (1), Love (2), Anger (3), Fear (4), and Surprise (5).
# Map labels to emotion types
label_mapping = {
    0: "Sadness",
    1: "Joy",
    2: "Love",
    3: "Anger",
    4: "Fear",
    5: "Surprise"
}
data["label"] = data["label"].map(label_mapping)

# Convert boolean columns to integers
for col in data.select_dtypes(include='bool'):
    data[col] = data[col].astype(int)

# Drop the original label column
#data.drop("label", axis=1, inplace=True)

# Display the first few rows
data.head()

"""**Step 5- Visualizing the distribution of each emotions**"""

# visualize the emotions using pie chart
# Count the occurrences of each emotion
emotion_counts = data["label"].value_counts()

# Plotting the pie chart
plt.figure(figsize=(8, 8))
plt.pie(emotion_counts, labels=emotion_counts.index, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired.colors)

"""**Step 6- Separating each emotions into different dataset to visualize the frequency of words in each emotion**

Separating each emotion into its own dataset allows us to independently analyze the text associated with each emotion category. This helps in understanding the distinct characteristics and word frequency patterns of the data for each emotion. It has the following purposes.

- Understanding Emotion-Specific Language
- Visualization of Word Frequencies
- Data Cleaning Validation
- Feature Engineering
"""

# Make Seperate Data Set to Visualize text
# Sadness
data_sadness = data[data['label']=='Sadness']
# Joy
data_joy = data[data['label']=='Joy']
# Love
data_love = data[data['label']=='Love']
# Anger
data_anger = data[data['label']=='Anger']
# Fear
data_fear = data[data['label']=='Fear']
# Surprise
data_surprise = data[data['label']=='Surprise']

# Combine text from different categories
sadness_text = ' '.join(data_sadness['text'])
joy_text = ' '.join(data_joy['text'])
love_text = ' '.join(data_love['text'])
anger_text = ' '.join(data_anger['text'])
fear_text = ' '.join(data_fear['text'])
surprise_text = ' '.join(data_surprise['text'])

#Generate a word cloud:
wordcloud_sadness = WordCloud(width=800, height=400, background_color='white').generate(sadness_text)
wordcloud_joy = WordCloud(width=800, height=400, background_color='white').generate(joy_text)
wordcloud_love = WordCloud(width=800, height=400, background_color='white').generate(love_text)
wordcloud_anger = WordCloud(width=800, height=400, background_color='white').generate(anger_text)
wordcloud_fear = WordCloud(width=800, height=400, background_color='white').generate(fear_text)
wordcloud_surprise = WordCloud(width=800, height=400, background_color='white').generate(surprise_text)

# Plot the word clouds
plt.figure(figsize=(18, 9))

plt.subplot(2, 3, 1)
plt.imshow(wordcloud_sadness, interpolation='bilinear')
plt.title('Sadness Text')
plt.axis('off')

plt.subplot(2, 3, 2)
plt.imshow(wordcloud_joy, interpolation='bilinear')
plt.title('Joy Text')
plt.axis('off')

plt.subplot(2, 3, 3)
plt.imshow(wordcloud_love, interpolation='bilinear')
plt.title('Love Text')
plt.axis('off')

plt.subplot(2, 3, 4)
plt.imshow(wordcloud_anger, interpolation='bilinear')
plt.title('Anger Text')
plt.axis('off')

plt.subplot(2, 3, 5)
plt.imshow(wordcloud_fear, interpolation='bilinear')
plt.title('Fear Text')
plt.axis('off')

plt.subplot(2, 3, 6)
plt.imshow(wordcloud_surprise, interpolation='bilinear')
plt.title('Surprise Text')
plt.axis('off')

plt.tight_layout()
plt.show()

# Mapping emotions to numerical labels
label_mapping = {
    'Sadness': 0,
    'Joy': 1,
    'Love': 2,
    'Anger': 3,
    'Fear': 4,
    'Surprise': 5
}

# Replace labels using the mapping
data['label'] = data['label'].replace(label_mapping)
data.head()

"""**Step 7- Text Preprocessing**

**Convert to Lowercase**:Ensures all text is in the same case, making comparisons consistent.

**Remove Non-Alphabetic Characters**:Removes numbers, punctuation, and special characters helps to focus only on words.

**Tokenize and Remove Stopwords**:Splits the text into individual words (tokens) and Removes common stopwords help to focus on more meaningful words.

**Lemmatize Words**: Converts words to their base or root form, ensuring consistency and reducing redundancy.

**Join Words Back Into a Single String**:Reassembles the cleaned tokens into a single string for compatibility with downstream tasks.
"""

# Download necessary NLTK data
nltk.download('stopwords')
nltk.download('wordnet')

# Initialize tools
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    # Convert to lowercase
    text = text.lower()

    # Remove non-alphabetic characters
    text = re.sub(r'[^a-z\s]', '', text)

    # Tokenize and remove stopwords
    words = text.split()
    words = [word for word in words if word not in stop_words]

    # Lemmatize words
    words = [lemmatizer.lemmatize(word) for word in words]

    # Join words back into a single string
    return ' '.join(words)

#Remove URLs
data['text'] = data['text'].str.replace(r'http\S+', '', regex=True)
# Apply preprocessing
data["text"] = data["text"].apply(preprocess_text)
# Display the first few rows of the DataFrame to verify the changes
print(data.head())

"""**Step 8- Split the data**"""

#Split the data into training (90%) and testing (10%):
# Split the data
X_train, X_test, y_train, y_test = train_test_split(
    data['text'],  # Features (the messages)
    data['label'],  # Labels (the emotion categories)
    test_size=0.1,  # 10% for testing
    random_state=42  # Ensure reproducibility
)

print("Training samples:", len(X_train))
print("Testing samples:", len(X_test))
print("Training samples(y_train):", len(y_train))
print("Testing samples(y_test):", len(y_test))

# Count the number of words in each text message for the training data:
X_train_lengths = X_train.apply(lambda x: len(x.split()))
print("Average words per message in training data:", X_train_lengths.mean())

# Count the number of words in each text message for the test data:
X_test_lengths = X_test.apply(lambda x: len(x.split()))
print("Average words per message in test data:", X_test_lengths.mean())

"""**Step 9- Tokenization and Padding Sequences**

Converts text data into numerical data by assigning a unique integer to each word based on its frequency and Padding ensures consistency in input dimensions.

"""

# Tokenize the texts
tokenizer = Tokenizer(num_words=50000)
tokenizer.fit_on_texts(X_train)
tokenizer.fit_on_texts(X_test)

# Convert texts to sequences
X_train_seq = tokenizer.texts_to_sequences(X_train)
X_test_seq = tokenizer.texts_to_sequences(X_test)

# Max Len in X_train_sequences
maxlen = max(len(tokens) for tokens in X_train_seq)


# Pad sequences to have the same length
X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen,padding='post')
X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen,padding='post')

# Embedding Input Size
input_size = np.max(X_train_pad) + 1
input_size

"""**Step 10- Define the model**

The model is constructed with the following steps
1. Define the Model
2. Add an Embedding Layer
3. Add a Bidirectional LSTM Layer
4. Add Batch Normalization Layer
5. Add Dropout Regularization
6. Add a Dense Layer with ReLU Activation
7. Add Another Dropout Layer
8. Add the Output Layer

"""

# Define the model
model = Sequential()

# Add an embedding layer
model.add(Embedding(input_dim=input_size, output_dim=100,input_shape=(79,)))

# Add a bidirectional GRU layer with 128 units
model.add(Bidirectional(LSTM(128)))

# Add batch normalization layer
model.add(BatchNormalization())

# Add dropout regularization
model.add(Dropout(0.5))

# Add a dense layer with 64 units and ReLU activation
model.add(Dense(64, activation='relu'))

# Add dropout regularization
model.add(Dropout(0.5))

# Add the output layer with 6 units for 6 labels and softmax activation
model.add(Dense(6, activation='softmax'))
# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Display the model summary
model.summary()

"""**Step 11- Fit the model**"""

# Perform multiple training runs to evaluate the model's performance
n_runs = 5  # Number of times the model will be trained and evaluated
metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}

for _ in range(n_runs):
    # Train the model on the training dataset with validation on the test dataset
    model.fit(X_train_pad, y_train,validation_data=(X_test_pad, y_test))
    # Generate predictions for the test dataset
    y_predd = model.predict(X_test_pad)
    y_pred = np.argmax(y_predd, axis=1) # Convert predictions to class labels
    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')

    # Store metrics in the dictionary
    metrics['accuracy'].append(accuracy)
    metrics['precision'].append(precision)
    metrics['recall'].append(recall)
    metrics['f1'].append(f1)

# Compute and display the mean and standard deviation of each metric across all runs
for metric, values in metrics.items():
    print(f"{metric.capitalize()}: Mean = {np.mean(values):.2f}, Std = {np.std(values):.2f}")

"""**Step 12: Confusion Matrix**"""

# y_test and y_pred are your true and predicted labels
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix with blue color
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

"""**Step 13: visualize the Receiver Operating Characteristic (ROC) curves and the corresponding Area Under the Curve (AUC)**
- helps to evaluate the model's ability to distinguish between different classes.
- A high AUC (close to 1.0) indicates excellent separability, while a low AUC (close to 0.5) indicates poor separability.
"""

# Binarize labels for multi-class ROC-AUC
y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3, 4, 5])
n_classes = y_test_binarized.shape[1]
# Compute ROC curve and AUC for each class
plt.figure()
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_predd[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"Class {i} (area = {roc_auc:.2f})")

# Plot settings
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve for Each Class")
plt.legend(loc="lower right")
plt.show()

